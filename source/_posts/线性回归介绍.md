---
title: 线性回归介绍
date: 2019-03-27 15:40:12
categories: 
- 机器学习
tags:
- 回归
---
还是对网上资料的整合提精，加一些自己的理解，可通过链接戳进原文。
<!--more-->

### 1 [线性回归假设](https://zhuanlan.zhihu.com/p/45427806)

1 假设1：回归分析模型是**正确设定**的。
    
> 如果把一个小朋友的饭量作为自变量、中国的GDP作为因变量做一个回归分析，很可能回归分析结果是显著的。但是，我们不能据此就说这个小朋友的饭量显著影响了中国的GDP。可见，如果回归分析模型设定错误，即使回归分析结果显著，也不能得到有意义的结论。

- 就是你想去回归的问题是正确的，即自变量线性组合生成因变量这件事情本身是正确的。

2 假设2：自变量x服从正态分布。

> 这条假设的目的是为了让对整个回归分析模型的**F检验和对某个参数的t检验**有效，但是，这是一条非常强的假设。很多来自实际的数据并不满足这条假设，比如0-1虚拟变量不能满足这条假设，但在回归分析模型中0-1虚拟变量却得到广泛应用，这是为什么呢？其实，为了保证F检验和t检验有效，只需要求残差服从正态分布即可。所谓残差就是因变量的真实值与预测值之差。所谓预测值就是在估计出来回归方程中的参数以后，把自变量带入回归方程中去所得到的因变量数值。换言之，即便是自变量x不服从正态分布，**只要残差服从正态分布，也可以保障F检验和t检验有效**。

- F检验：方差分析(或译变异数分析，Analysis of  Variance)，它的原理大致也是上面说的，但它是透过检视变量的方差而进行的
- t检验：t检验过程，是对两样本均数(mean)差别的显著性进行检验。惟t检验须知道两个总体的方差(Variances)是否相等；t检验值的计算会因方差是否相等而有所不同。也就是说，t检验须视乎方差齐性(Equality of Variances)结果。

3 假设3：**在给定自变量x的情况下，随机误差项μ的均值为0，μ与x同方差**，**μ与x不序列相关**。

> 这一假设表明：**随机误差项μ和自变量x不具有任何形式的相关性**。这一假设意味着，**随机误差项的方差不随着自变量的变化而变化**。如果这一假设成立，自变量x就被称为外生解释变量；如果这一假设不成立，自变量x就被称为内生解释变量。从表面上看，这一假设是否成立是由统计分析结果决定的；从实际上看，这一假设是否成立取决于回归分析模型设定是否合理。**如果回归分析模型中的自变量就是因变量的最主要影响因素**，而且自变量不受到模型之外的其他因素影响，那么，自变量自然就与随机因素无关了。反之，如果回归分析模型中的自变量虽然是因变量的影响因素之一，但自变量受到了尚未包含在模型中的其他因素的影响，那么，自变量就会与随机因素有关了。

4 假设4：因变量x在所抽样本中具有**变异性**，而且随着样本量的增加，因变量x的**方差**趋近于一个非零常数。

> 这一假设的**前半部分**（因变量x在所抽样本中具有变异性）是由回归分析的本质所决定的，回归分析就是基于自变量x的变化来解释因变量y的变化的。如果所有自变量x都处于同一水平值上，无论因变量如何变化，也无法估计出自变量的系数。
> 这一假设的后半部分（随着样本量的增加，因变量x的方差趋近于一个非零常数），旨在**排除时间序列数据**中持续上升或下降的变量作为自变量，这类数据不仅使得统计推断无效，还会产生其他问题。

5 假设5：**随机误差项μ服从零均值、同方差的正态分布**。

![avater](1.png)

> 这一假设的目的在于保证**统计推断的可靠性**。当样本量不大时，这条假设必须得到重视；当样本量非常大时，可以放松这条假设，因为由**中心极限定理**可知，当样本量足够大时，随机误差项的分布接近正态分布。

6 假设6：各个自变量之间不存在严格线性相关性。
> 这一假设是多元线性回归分析所特有的，这一假设可以写成：n×（k+1）矩阵X的秩为（k+1），即矩阵X满秩，其中n为样本数，k为自变量的个数。从本质上讲，这一假设是计算过程所要求的，如果矩阵X并非满秩，就无法估计出（k+1）个需要估计的参数，包括k个自变量的系数，1个常数项。

- 在宋线线同志的帮助下，终于搞懂了，见下图
![avater](2.jpg)


### 参考
- https://zhuanlan.zhihu.com/p/45427806
